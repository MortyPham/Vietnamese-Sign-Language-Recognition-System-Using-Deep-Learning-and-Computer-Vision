{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4HgBteW3wnW"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip -q install ultralytics roboflow==1.* rich\n",
        "import os, shutil, json, yaml, re, glob, random, math\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter, defaultdict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary datasets\n",
        "!rm -rf \"/content/VIETNAM-SIGN-LANGUAGE-7\"\n",
        "\n",
        "from roboflow import Roboflow\n",
        "import os\n",
        "os.environ[\"ROBOFLOW_API_KEY\"] = \"aqOzlejG9d4xpiYBF3JI\"\n",
        "\n",
        "rf = Roboflow(api_key=os.environ[\"ROBOFLOW_API_KEY\"])\n",
        "project = rf.workspace(\"ho-chi-minh-university-of-technology-clmwp\").project(\"vietnam-sign-language\")\n",
        "version = project.version(7)\n",
        "dataset = version.download(\"yolov8\")\n",
        "print(\"Location:\", dataset.location)\n"
      ],
      "metadata": {
        "id": "IRgZLBgJMK4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Reshape to YOLO shape \"\"\"\n",
        "root = Path(dataset.location)\n",
        "print(root)\n",
        "\n",
        "if (root/\"valid\").exists() and not (root/\"val\").exists():\n",
        "    (root/\"valid\").rename(root/\"val\")\n",
        "\n",
        "def ensure_ultralytics_layout(root: Path):\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        if not (root/split).exists():\n",
        "            continue\n",
        "        (root/\"images\"/split).mkdir(parents=True, exist_ok=True)\n",
        "        (root/\"labels\"/split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        if (root/split/\"images\").exists():\n",
        "            for p in (root/split/\"images\").glob(\"*\"):\n",
        "                shutil.move(str(p), str(root/\"images\"/split/p.name))\n",
        "        else:\n",
        "            for p in (root/split).glob(\"*\"):\n",
        "                if p.suffix.lower() in [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"]:\n",
        "                    shutil.move(str(p), str(root/\"images\"/split/p.name))\n",
        "\n",
        "        if (root/split/\"labels\").exists():\n",
        "            for p in (root/split/\"labels\").glob(\"*.txt\"):\n",
        "                shutil.move(str(p), str(root/\"labels\"/split/p.name))\n",
        "        else:\n",
        "            for p in (root/split).glob(\"*.txt\"):\n",
        "                shutil.move(str(p), str(root/\"labels\"/split/p.name))\n",
        "\n",
        "        try:\n",
        "            shutil.rmtree(root/split)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "ensure_ultralytics_layout(root)\n",
        "\n",
        "data_yaml = root/\"data.yaml\"\n",
        "with open(data_yaml) as f:\n",
        "    data = yaml.safe_load(f)\n",
        "\n",
        "data[\"path\"] = str(root.resolve())\n",
        "data[\"train\"] = \"images/train\"\n",
        "data[\"val\"]   = \"images/val\"\n",
        "if (root/\"images/test\").exists():\n",
        "    data[\"test\"]  = \"images/test\"\n",
        "\n",
        "with open(data_yaml, \"w\") as f:\n",
        "    yaml.safe_dump(data, f, sort_keys=False)\n",
        "\n",
        "print(\"Classes:\", data.get(\"names\"))\n"
      ],
      "metadata": {
        "id": "hznspCbj7OnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Divide into train, val, test \"\"\"\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import shutil, yaml\n",
        "\n",
        "ROOT   = Path(\"/content/VIETNAM-SIGN-LANGUAGE-7\")  # dataset root\n",
        "RATIOS = (0.70, 0.20, 0.10)  # train, val, test\n",
        "SEED   = 42\n",
        "IMG_EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"}\n",
        "\n",
        "# Collect pairs (image, label)\n",
        "def find_pairs(root: Path):\n",
        "    pairs = []\n",
        "    for sp in [\"train\",\"val\",\"test\"]:\n",
        "        img_dir = root/\"images\"/sp\n",
        "        lbl_dir = root/\"labels\"/sp\n",
        "        if img_dir.exists() and lbl_dir.exists():\n",
        "            for img in img_dir.iterdir():\n",
        "                if img.suffix.lower() in IMG_EXTS:\n",
        "                    lbl = lbl_dir/(img.stem + \".txt\")\n",
        "                    if lbl.exists():\n",
        "                        pairs.append((img, lbl))\n",
        "    return pairs\n",
        "\n",
        "# Handle class for stratification\n",
        "def majority_class(lbl_path: Path):\n",
        "    try:\n",
        "        with open(lbl_path) as f:\n",
        "            lines = [ln.strip() for ln in f if ln.strip()]\n",
        "        if not lines:\n",
        "            return 0\n",
        "        counts = Counter(int(ln.split()[0]) for ln in lines)\n",
        "        return counts.most_common(1)[0][0]\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "pairs = find_pairs(ROOT)\n",
        "print(f\"Found {len(pairs)} image/label pairs\")\n",
        "\n",
        "# Re-split dataset\n",
        "y_all = [majority_class(lbl) for _, lbl in pairs]\n",
        "\n",
        "train_pairs, temp_pairs, y_train, y_temp = train_test_split(\n",
        "    pairs, y_all, test_size=(1.0 - RATIOS[0]), random_state=SEED, stratify=y_all\n",
        ")\n",
        "\n",
        "val_portion = RATIOS[1] / (RATIOS[1] + RATIOS[2])\n",
        "val_pairs, test_pairs, _, _ = train_test_split(\n",
        "    temp_pairs, y_temp, test_size=(1 - val_portion), random_state=SEED, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Place into new folders\n",
        "out_root = ROOT/\"split_70_20_10\"\n",
        "for sp in [\"train\",\"val\",\"test\"]:\n",
        "    (out_root/\"images\"/sp).mkdir(parents=True, exist_ok=True)\n",
        "    (out_root/\"labels\"/sp).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def place(pairs, split):\n",
        "    for img, lbl in pairs:\n",
        "        shutil.copy2(img, out_root/\"images\"/split/img.name)\n",
        "        shutil.copy2(lbl, out_root/\"labels\"/split/lbl.name)\n",
        "\n",
        "place(train_pairs, \"train\")\n",
        "place(val_pairs,   \"val\")\n",
        "place(test_pairs,  \"test\")\n",
        "\n",
        "# Write data.yaml\n",
        "data = {\n",
        "    \"path\": str(out_root.resolve()),\n",
        "    \"train\": \"images/train\",\n",
        "    \"val\": \"images/val\",\n",
        "    \"test\": \"images/test\",\n",
        "}\n",
        "yaml.safe_dump(data, open(out_root/\"data.yaml\",\"w\"), sort_keys=False)\n",
        "\n",
        "for sp in [\"train\",\"val\",\"test\"]:\n",
        "    ni = len(list((out_root/\"images\"/sp).glob(\"*\")))\n",
        "    nl = len(list((out_root/\"labels\"/sp).glob(\"*.txt\")))\n",
        "    print(f\"{sp}: {ni} images, {nl} labels\")\n"
      ],
      "metadata": {
        "id": "eZlsd1BZIU8h",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(root/\"data.yaml\") as f:\n",
        "    data = yaml.safe_load(f)\n",
        "names = data.get(\"names\", [])\n",
        "nc = data.get(\"nc\", len(names)) or len(names)\n",
        "if not names:\n",
        "    names = [str(i) for i in range(nc)]\n",
        "print(f\"Classes ({len(names)}):\", names)\n"
      ],
      "metadata": {
        "id": "PICL_HEAK2zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of images and labels of each class\n",
        "\n",
        "def yolo_box_counter(label_file):\n",
        "    cnt = Counter()\n",
        "    with open(label_file) as f:\n",
        "        for line in f:\n",
        "            cid = int(line.strip().split()[0])\n",
        "            cnt[cid] += 1\n",
        "    return cnt\n",
        "\n",
        "split_stats = {}\n",
        "class_counts = Counter()\n",
        "\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    img_dir = root/\"images\"/split\n",
        "    lbl_dir = root/\"labels\"/split\n",
        "    imgs = list(img_dir.glob(\"*\"))\n",
        "    lbls = list(lbl_dir.glob(\"*.txt\"))\n",
        "    n_imgs = len(imgs)\n",
        "    n_lbls = 0\n",
        "    for lf in lbls:\n",
        "        c = yolo_box_counter(lf)\n",
        "        n_lbls += sum(c.values())\n",
        "        class_counts.update(c)\n",
        "    split_stats[split] = {\"images\": n_imgs, \"boxes\": n_lbls}\n",
        "\n",
        "split_stats, class_counts\n"
      ],
      "metadata": {
        "id": "rsePzFaxK9zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class distribution + imbalance ratio + bar chart\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import yaml, matplotlib.pyplot as plt\n",
        "\n",
        "ROOT = Path(\"/content/VIETNAM-SIGN-LANGUAGE-7\")\n",
        "IMG_EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\"}\n",
        "\n",
        "with open(ROOT/\"data.yaml\") as f:\n",
        "    data = yaml.safe_load(f)\n",
        "names = data.get(\"names\", [])\n",
        "nc = len(names)\n",
        "\n",
        "def yolo_box_counter(label_file: Path):\n",
        "    c = Counter()\n",
        "    with open(label_file) as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if not parts:\n",
        "                continue\n",
        "            try:\n",
        "                cid = int(parts[0])\n",
        "                c[cid] += 1\n",
        "            except:\n",
        "                pass\n",
        "    return c\n",
        "\n",
        "def split_dirs(split):\n",
        "    if (ROOT/split/\"images\").exists() and (ROOT/split/\"labels\").exists():\n",
        "        return ROOT/split/\"images\", ROOT/split/\"labels\"\n",
        "    if (ROOT/\"images\"/split).exists() and (ROOT/\"labels\"/split).exists():\n",
        "        return ROOT/\"images\"/split, ROOT/\"labels\"/split\n",
        "    return None, None\n",
        "\n",
        "per_split_counts = {}\n",
        "total_counts = Counter()\n",
        "for sp in [\"train\",\"val\",\"test\",\"valid\"]:\n",
        "    img_dir, lbl_dir = split_dirs(sp)\n",
        "    if not img_dir:\n",
        "        continue\n",
        "    c = Counter()\n",
        "    for lf in lbl_dir.glob(\"*.txt\"):\n",
        "        c.update(yolo_box_counter(lf))\n",
        "    per_split_counts[\"val\" if sp==\"valid\" else sp] = c\n",
        "    total_counts.update(c)\n",
        "\n",
        "vals = [total_counts.get(i, 0) for i in range(nc)]\n",
        "\n",
        "nonzero = [v for v in vals if v > 0]\n",
        "imbalance_ratio = (max(nonzero) / min(nonzero)) if nonzero else float(\"nan\")\n",
        "\n",
        "print(\"Number of bbox per split:\")\n",
        "for sp, c in per_split_counts.items():\n",
        "    print(f\"  {sp:>5}: {sum(c.values())} boxes\")\n",
        "print(f\"\\nImbalance ratio (max/min,): {imbalance_ratio:.2f}\")\n",
        "\n",
        "if nonzero:\n",
        "    max_i = vals.index(max(vals))\n",
        "    min_i = vals.index(min(nonzero))\n",
        "    print(f\"  Max: {names[max_i]} = {vals[max_i]}\")\n",
        "    print(f\"  Min : {names[min_i]} = {vals[min_i]}\")\n",
        "missing = [names[i] for i,v in enumerate(vals) if v==0]\n",
        "if missing:\n",
        "    print(\"missing\", missing)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar([names[i] for i in range(nc)], vals)\n",
        "plt.title(\"Bounding box in each class\")\n",
        "plt.xlabel(\"class\"); plt.ylabel(\"Bounding box\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qujpv3xRPFBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_label_file(path, nc):\n",
        "    bad = {\"class_out_of_range\":0, \"coords_out_of_range\":0, \"zero_box\":0, \"format_error\":0}\n",
        "    with open(path) as f:\n",
        "        for ln in f:\n",
        "            parts = ln.strip().split()\n",
        "            if len(parts)!=5:\n",
        "                bad[\"format_error\"]+=1; continue\n",
        "            c, x, y, w, h = parts\n",
        "            try:\n",
        "                c = int(c); x=float(x); y=float(y); w=float(w); h=float(h)\n",
        "            except:\n",
        "                bad[\"format_error\"]+=1; continue\n",
        "            if c<0 or c>=nc: bad[\"class_out_of_range\"]+=1\n",
        "            if w<=0 or h<=0: bad[\"zero_box\"]+=1\n",
        "            for v in (x,y,w,h):\n",
        "                if v<0 or v>1: bad[\"coords_out_of_range\"]+=1; break\n",
        "    return bad\n",
        "\n",
        "errors = Counter()\n",
        "for lf in root.rglob(\"labels/*.txt\"):\n",
        "    e = check_label_file(lf, len(names))\n",
        "    errors.update(e)\n",
        "\n",
        "print(\"Label issues:\", dict(errors))\n"
      ],
      "metadata": {
        "id": "Q1z1-LroR1i5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(p): return p.stem\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    imgs = {p.stem for p in (root/\"images\"/split).glob(\"*\")}\n",
        "    lbls = {p.stem for p in (root/\"labels\"/split).glob(\"*.txt\")}\n",
        "    print(split,\n",
        "          \"no_label:\", len(imgs - lbls),\n",
        "          \"no_image:\", len(lbls - imgs))\n"
      ],
      "metadata": {
        "id": "34crsfkyR5HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8n.pt\")  # small model\n",
        "model.train(data=str(root/\"data.yaml\"), epochs=1, imgsz=640, device=0)\n"
      ],
      "metadata": {
        "id": "K-G_KDk2SJcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to dataset\n",
        "DATASET_DIR = \"/content/VIETNAM-SIGN-LANGUAGE-7\"\n",
        "TARGET_DIR  = \"/content/drive/MyDrive/vietnam_sign_language_resplit\"\n",
        "\n",
        "# Remove old copy if exists\n",
        "if os.path.exists(TARGET_DIR):\n",
        "    shutil.rmtree(TARGET_DIR)\n",
        "\n",
        "# Copy the entire dataset folder to Google Drive\n",
        "shutil.copytree(DATASET_DIR, TARGET_DIR)\n",
        "\n",
        "print(f\"Dataset saved to: {TARGET_DIR}\")\n"
      ],
      "metadata": {
        "id": "sAGHi94_bN02"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}